{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jraph in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (0.0.6.dev0)\n",
      "Requirement already satisfied: flax in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (0.10.4)\n",
      "Requirement already satisfied: dm-haiku in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (0.0.13)\n",
      "Requirement already satisfied: matplotlib in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (3.8.4)\n",
      "Requirement already satisfied: networkx in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (3.2.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: ogb in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (1.3.6)\n",
      "Requirement already satisfied: jax>=0.1.55 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from jraph) (0.5.2)\n",
      "Requirement already satisfied: jaxlib>=0.1.37 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from jraph) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from jraph) (1.26.4)\n",
      "Requirement already satisfied: msgpack in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from flax) (1.1.0)\n",
      "Requirement already satisfied: optax in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from flax) (0.2.4)\n",
      "Requirement already satisfied: orbax-checkpoint in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from flax) (0.11.8)\n",
      "Requirement already satisfied: tensorstore in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from flax) (0.1.72)\n",
      "Requirement already satisfied: rich>=11.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from flax) (13.9.4)\n",
      "Requirement already satisfied: typing_extensions>=4.2 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from flax) (4.12.2)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from flax) (6.0.2)\n",
      "Requirement already satisfied: treescope>=0.1.7 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from flax) (0.1.9)\n",
      "Requirement already satisfied: absl-py>=0.7.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from dm-haiku) (2.1.0)\n",
      "Requirement already satisfied: jmp>=0.0.2 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from dm-haiku) (0.0.4)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from dm-haiku) (0.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from ogb) (2.5.0)\n",
      "Requirement already satisfied: tqdm>=4.29.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from ogb) (4.67.1)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from ogb) (2.2.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from ogb) (1.16.0)\n",
      "Requirement already satisfied: urllib3>=1.24.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from ogb) (2.3.0)\n",
      "Requirement already satisfied: outdated>=0.2.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from ogb) (0.2.2)\n",
      "Requirement already satisfied: ml_dtypes>=0.4.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from jax>=0.1.55->jraph) (0.5.1)\n",
      "Requirement already satisfied: opt_einsum in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from jax>=0.1.55->jraph) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=44 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (75.8.0)\n",
      "Requirement already satisfied: littleutils in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (0.2.4)\n",
      "Requirement already satisfied: requests in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from pandas>=0.24.0->ogb) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from rich>=11.1->flax) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from rich>=11.1->flax) (2.15.1)\n",
      "Requirement already satisfied: filelock in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.18.0)\n",
      "Requirement already satisfied: jinja2 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (3.1.5)\n",
      "Requirement already satisfied: fsspec in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (2025.3.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.6.0->ogb) (1.3.0)\n",
      "Requirement already satisfied: chex>=0.1.87 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from optax->flax) (0.1.89)\n",
      "Requirement already satisfied: etils[epy] in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from optax->flax) (1.12.2)\n",
      "Requirement already satisfied: nest_asyncio in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from orbax-checkpoint->flax) (1.6.0)\n",
      "Requirement already satisfied: protobuf in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from orbax-checkpoint->flax) (6.30.1)\n",
      "Requirement already satisfied: humanize in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from orbax-checkpoint->flax) (4.12.1)\n",
      "Requirement already satisfied: simplejson>=3.16.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from orbax-checkpoint->flax) (3.20.1)\n",
      "Requirement already satisfied: toolz>=0.9.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from chex>=0.1.87->optax->flax) (1.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax) (0.1.2)\n",
      "Requirement already satisfied: importlib_resources in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (6.5.2)\n",
      "Requirement already satisfied: zipp in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from etils[epath,epy]->orbax-checkpoint->flax) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (3.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages (from requests->outdated>=0.2.0->ogb) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip install jraph flax dm-haiku matplotlib networkx scikit-learn ogb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import functools\n",
    "import matplotlib.pyplot as plt\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.tree_util as tree\n",
    "import jraph\n",
    "import flax\n",
    "import haiku as hk\n",
    "import optax\n",
    "import pickle\n",
    "import numpy as onp\n",
    "import networkx as nx\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_self_edges_fn(receivers: jnp.ndarray, senders: jnp.ndarray,\n",
    "                      total_num_nodes: int) -> Tuple[jnp.ndarray, jnp.ndarray]:\n",
    "    \"\"\"Adds self edges. Assumes self edges are not in the graph yet.\"\"\"\n",
    "    receivers = jnp.concatenate((receivers, jnp.arange(total_num_nodes)), axis=0)\n",
    "    senders = jnp.concatenate((senders, jnp.arange(total_num_nodes)), axis=0)\n",
    "    return receivers, senders\n",
    "\n",
    "class MLP(hk.Module):\n",
    "    def __init__(self, features: jnp.ndarray):\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "\n",
    "    def __call__(self, x: jnp.ndarray) -> jnp.ndarray:\n",
    "        layers = []\n",
    "        for feat in self.features[:-1]:\n",
    "            layers.append(hk.Linear(feat))\n",
    "            layers.append(jax.nn.relu)\n",
    "            layers.append(hk.Linear(self.features[-1]))\n",
    "\n",
    "        mlp = hk.Sequential(layers)\n",
    "        return mlp(x)\n",
    "\n",
    "# Use MLP block to define the update node function\n",
    "update_node_fn = lambda x: MLP(features=[8, 4])(x)\n",
    "\n",
    "# Adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L506\n",
    "def GraphConvolution(update_node_fn: Callable,\n",
    "                     aggregate_nodes_fn: Callable = jax.ops.segment_sum,\n",
    "                     add_self_edges: bool = False,\n",
    "                     symmetric_normalization: bool = True) -> Callable:\n",
    "  \"\"\"Returns a method that applies a Graph Convolution layer.\n",
    "\n",
    "  Graph Convolutional layer as in https://arxiv.org/abs/1609.02907,\n",
    "  NOTE: This implementation does not add an activation after aggregation.\n",
    "  If you are stacking layers, you may want to add an activation between\n",
    "  each layer.\n",
    "  Args:\n",
    "    update_node_fn: function used to update the nodes. In the paper a single\n",
    "      layer MLP is used.\n",
    "    aggregate_nodes_fn: function used to aggregates the sender nodes.\n",
    "    add_self_edges: whether to add self edges to nodes in the graph as in the\n",
    "      paper definition of GCN. Defaults to False.\n",
    "    symmetric_normalization: whether to use symmetric normalization. Defaults to\n",
    "      True.\n",
    "\n",
    "  Returns:\n",
    "    A method that applies a Graph Convolution layer.\n",
    "  \"\"\"\n",
    "\n",
    "  def _ApplyGCN(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Convolution layer.\"\"\"\n",
    "    nodes, _, receivers, senders, _, _, _ = graph\n",
    "\n",
    "    # First pass nodes through the node updater.\n",
    "    nodes = update_node_fn(nodes)\n",
    "    # Equivalent to jnp.sum(n_node), but jittable\n",
    "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
    "    if add_self_edges:\n",
    "      # We add self edges to the senders and receivers so that each node\n",
    "      # includes itself in aggregation.\n",
    "      # In principle, a `GraphsTuple` should partition by n_edge, but in\n",
    "      # this case it is not required since a GCN is agnostic to whether\n",
    "      # the `GraphsTuple` is a batch of graphs or a single large graph.\n",
    "      conv_receivers, conv_senders = add_self_edges_fn(receivers, senders,\n",
    "                                                       total_num_nodes)\n",
    "    else:\n",
    "      conv_senders = senders\n",
    "      conv_receivers = receivers\n",
    "\n",
    "    # pylint: disable=g-long-lambda\n",
    "    if symmetric_normalization:\n",
    "      # Calculate the normalization values.\n",
    "      count_edges = lambda x: jax.ops.segment_sum(\n",
    "          jnp.ones_like(conv_senders), x, total_num_nodes)\n",
    "      sender_degree = count_edges(conv_senders)\n",
    "      receiver_degree = count_edges(conv_receivers)\n",
    "\n",
    "      # Pre normalize by sqrt sender degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: x * jax.lax.rsqrt(jnp.maximum(sender_degree, 1.0))[:, None],\n",
    "          nodes,\n",
    "      )\n",
    "      # Aggregate the pre-normalized nodes.\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "      # Post normalize by sqrt receiver degree.\n",
    "      # Avoid dividing by 0 by taking maximum of (degree, 1).\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x:\n",
    "          (x * jax.lax.rsqrt(jnp.maximum(receiver_degree, 1.0))[:, None]),\n",
    "          nodes,\n",
    "      )\n",
    "    else:\n",
    "      nodes = tree.tree_map(\n",
    "          lambda x: aggregate_nodes_fn(x[conv_senders], conv_receivers,\n",
    "                                       total_num_nodes), nodes)\n",
    "    # pylint: enable=g-long-lambda\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  return _ApplyGCN\n",
    "\n",
    "# GAT implementation adapted from https://github.com/deepmind/jraph/blob/master/jraph/_src/models.py#L442.\n",
    "def GAT(attention_query_fn: Callable,\n",
    "        attention_logit_fn: Callable,\n",
    "        node_update_fn: Optional[Callable] = None,\n",
    "        add_self_edges: bool = True) -> Callable:\n",
    "  \"\"\"Returns a method that applies a Graph Attention Network layer.\n",
    "\n",
    "  Graph Attention message passing as described in\n",
    "  https://arxiv.org/pdf/1710.10903.pdf. This model expects node features as a\n",
    "  jnp.array, may use edge features for computing attention weights, and\n",
    "  ignore global features. It does not support nests.\n",
    "  Args:\n",
    "    attention_query_fn: function that generates attention queries from sender\n",
    "      node features.\n",
    "    attention_logit_fn: function that converts attention queries into logits for\n",
    "      softmax attention.\n",
    "    node_update_fn: function that updates the aggregated messages. If None, will\n",
    "      apply leaky relu and concatenate (if using multi-head attention).\n",
    "\n",
    "  Returns:\n",
    "    A function that applies a Graph Attention layer.\n",
    "  \"\"\"\n",
    "  # pylint: disable=g-long-lambda\n",
    "  if node_update_fn is None:\n",
    "    # By default, apply the leaky relu and then concatenate the heads on the\n",
    "    # feature axis.\n",
    "    node_update_fn = lambda x: jnp.reshape(\n",
    "        jax.nn.leaky_relu(x), (x.shape[0], -1))\n",
    "\n",
    "  def _ApplyGAT(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "    \"\"\"Applies a Graph Attention layer.\"\"\"\n",
    "    nodes, edges, receivers, senders, _, _, _ = graph\n",
    "    # Equivalent to the sum of n_node, but statically known.\n",
    "    try:\n",
    "      sum_n_node = nodes.shape[0]\n",
    "    except IndexError:\n",
    "      raise IndexError('GAT requires node features')\n",
    "\n",
    "    # Pass nodes through the attention query function to transform\n",
    "    # node features, e.g. with an MLP.\n",
    "    nodes = attention_query_fn(nodes)\n",
    "\n",
    "    total_num_nodes = tree.tree_leaves(nodes)[0].shape[0]\n",
    "    if add_self_edges:\n",
    "      # We add self edges to the senders and receivers so that each node\n",
    "      # includes itself in aggregation.\n",
    "      receivers, senders = add_self_edges_fn(receivers, senders,\n",
    "                                             total_num_nodes)\n",
    "\n",
    "    # We compute the softmax logits using a function that takes the\n",
    "    # embedded sender and receiver attributes.\n",
    "    sent_attributes = nodes[senders]\n",
    "    received_attributes = nodes[receivers]\n",
    "    att_softmax_logits = attention_logit_fn(sent_attributes,\n",
    "                                            received_attributes, edges)\n",
    "\n",
    "    # Compute the attention softmax weights on the entire tree.\n",
    "    att_weights = jraph.segment_softmax(\n",
    "        att_softmax_logits, segment_ids=receivers, num_segments=sum_n_node)\n",
    "\n",
    "    # Apply attention weights.\n",
    "    messages = sent_attributes * att_weights\n",
    "    # Aggregate messages to nodes.\n",
    "    nodes = jax.ops.segment_sum(messages, receivers, num_segments=sum_n_node)\n",
    "\n",
    "    # Apply an update function to the aggregated messages.\n",
    "    nodes = node_update_fn(nodes)\n",
    "\n",
    "    return graph._replace(nodes=nodes)\n",
    "\n",
    "  # pylint: enable=g-long-lambda\n",
    "  return _ApplyGAT\n",
    "\n",
    "def attention_logit_fn(sender_attr: jnp.ndarray, receiver_attr: jnp.ndarray,\n",
    "                       edges: jnp.ndarray) -> jnp.ndarray:\n",
    "  del edges\n",
    "  x = jnp.concatenate((sender_attr, receiver_attr), axis=1)\n",
    "  return hk.Linear(1)(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fracapuano/miniconda3/envs/graphsenv/lib/python3.10/site-packages/ogb/nodeproppred/dataset.py:70: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_dict = torch.load(pre_processed_file_path)\n"
     ]
    }
   ],
   "source": [
    "from ogb.nodeproppred import NodePropPredDataset\n",
    "\n",
    "dataset = NodePropPredDataset(name = 'ogbn-arxiv')\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]\n",
    "\n",
    "# subsampling the number of nodes for computational reasons\n",
    "subnodes = 10_000\n",
    "train_idx = onp.random.choice(train_idx, size=subnodes, replace=False)\n",
    "valid_idx = onp.random.choice(valid_idx, size=subnodes//2, replace=False)\n",
    "test_idx = onp.random.choice(test_idx, size=subnodes//2, replace=False)\n",
    "\n",
    "graph, labels = dataset[0]\n",
    "\n",
    "def graph_to_jax_graph(graph: dict) -> jraph.GraphsTuple:\n",
    "    \"\"\"Returns a jax graph built from a dictionary representing a graph.\"\"\"\n",
    "    node_features = jnp.array(graph['node_feat'])\n",
    "    senders, receivers = jnp.array(graph['edge_index'])\n",
    "    edges = None\n",
    "    n_node = jnp.array([graph['num_nodes']])\n",
    "    n_edge = jnp.array([len(senders)])\n",
    "    global_context = jnp.array([[1]])  # dummy global\n",
    "\n",
    "    graph_jax = jraph.GraphsTuple(\n",
    "        nodes=node_features,\n",
    "        edges=edges,\n",
    "        senders=senders,\n",
    "        receivers=receivers,\n",
    "        n_node=n_node,\n",
    "        n_edge = n_edge,\n",
    "        globals=global_context\n",
    "    )\n",
    "    \n",
    "    return graph_jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_graph = graph_to_jax_graph(graph)\n",
    "arxiv_labels = jnp.array(labels)\n",
    "\n",
    "# indices for splits for aggregation\n",
    "train_mask = jnp.zeros(graph['num_nodes'], dtype=bool).at[train_idx].set(True)\n",
    "valid_mask = jnp.zeros(graph['num_nodes'], dtype=bool).at[valid_idx].set(True)\n",
    "test_mask = jnp.zeros(graph['num_nodes'], dtype=bool).at[test_idx].set(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_gcn_network(layers: list[int], n_classes: int):\n",
    "    def gcn_network(graph: jraph.GraphsTuple) -> jraph.GraphsTuple:\n",
    "        for x in layers: \n",
    "            gn = GraphConvolution(\n",
    "                update_node_fn=lambda n: jax.nn.relu(hk.Linear(x)(n)),\n",
    "                add_self_edges=True\n",
    "            )\n",
    "            \n",
    "            graph = gn(graph)\n",
    "\n",
    "        gn = GraphConvolution(\n",
    "            update_node_fn=hk.Linear(n_classes)\n",
    "        )\n",
    "        graph = gn(graph)\n",
    "        \n",
    "        return graph\n",
    "    \n",
    "    return gcn_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [128 for _ in range(3)]\n",
    "n_classes = len(set(labels.flatten()))\n",
    "\n",
    "network = hk.without_apply_rng(\n",
    "    hk.transform(\n",
    "        build_gcn_network(layers, n_classes)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_network(\n",
    "        network: hk.Transformed, \n",
    "        num_steps: int,\n",
    "    ) -> jnp.ndarray:\n",
    "    params = network.init(jax.random.PRNGKey(42), arxiv_graph)\n",
    "\n",
    "    opt_init, opt_update = optax.adam(1e-2)\n",
    "    opt_state = opt_init(params)\n",
    "\n",
    "    @jax.jit\n",
    "    def predict(params: hk.Params) -> jnp.ndarray:\n",
    "        decoded_graph = network.apply(params, arxiv_graph)\n",
    "        return jnp.argmax(decoded_graph.nodes, axis=1)\n",
    "\n",
    "    @jax.jit\n",
    "    def cross_entropy_loss(params: hk.Params) -> jnp.ndarray:\n",
    "        decoded_graph = network.apply(params, arxiv_graph)\n",
    "        log_prob = jax.nn.log_softmax(decoded_graph.nodes[train_mask])\n",
    "        target = jax.nn.one_hot(arxiv_labels[train_mask], n_classes)\n",
    "        return -jnp.sum(log_prob * target)\n",
    "\n",
    "\n",
    "    def update(params: hk.Params, opt_state) -> Tuple[hk.Params, Any]:\n",
    "        \"\"\"Returns updated params and state.\"\"\"\n",
    "        g = jax.grad(cross_entropy_loss)(params)\n",
    "        updates, opt_state = opt_update(g, opt_state)\n",
    "        return optax.apply_updates(params, updates), opt_state\n",
    "\n",
    "    @jax.jit\n",
    "    def accuracy(params: hk.Params) -> jnp.ndarray:\n",
    "        \"\"\"Computes the node-accuracy on the different splits created above.\"\"\"\n",
    "        decoded_graph = network.apply(params, arxiv_graph)\n",
    "        training_accuracy = jnp.mean(jnp.argmax(decoded_graph.nodes[train_mask], axis=1) == arxiv_labels[train_mask])\n",
    "        testing_accuracy = jnp.mean(jnp.argmax(decoded_graph.nodes[test_mask], axis=1) == arxiv_labels[test_mask])\n",
    "        overall_accuracy = jnp.mean(jnp.argmax(decoded_graph.nodes, axis=1) == arxiv_labels)\n",
    "        return training_accuracy, testing_accuracy, overall_accuracy\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        if step % 10 == 0:\n",
    "            print(f\"step {step} | train acc. {float(accuracy(params)[0])*100:.3f} % - test acc. {float(accuracy(params)[1])*100:.3f} % - overall acc. {float(accuracy(params)[2])*100:.3f} %\")\n",
    "\n",
    "        params, opt_state = update(params, opt_state)\n",
    "    return predict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimize_network(network, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphsenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
